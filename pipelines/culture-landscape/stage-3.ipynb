{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landscape map - stage 3\n",
    "\n",
    "This stage merges the raw longlist with the candidate data from the reference sources to create the new list.\n",
    "\n",
    "It round-trips the data from the existing landscape list to ensure that any manual overrides are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import petl as etl\n",
    "from pipeline_utils.reference.geo import la_code_lookup\n",
    "from pipeline_utils.reference.onspd import normalise_postcode, postcode_lookup\n",
    "from pipeline_utils.filesystem.paths import RAW_DATA, DATA\n",
    "from config import WORKING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the spelling corrections we have inferred from the matching stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections = etl.fromcsv(WORKING / '2-company-corrections.csv').lookupone('organisation', 'match')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the untagged longlist from the raw directory and perform the following operations:\n",
    "\n",
    "1. Convert numeric data to numbers\n",
    "2. Correct the spellings of the organisational data\n",
    "3. Augment with local authority data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = etl.fromcsv(\n",
    "    WORKING / 'funded-organisations.csv'\n",
    ").convertnumbers(\n",
    ").convert(\n",
    "    'organisation', lambda x: corrections.get(x, x)\n",
    ").convert(\n",
    "    'Local authority', la_code_lookup\n",
    ").unpackdict(\n",
    "    'Local authority'\n",
    ").rename({\n",
    "    'LAD24CD': 'funding_geo_code',\n",
    "    'LAD24NM': 'funding_geo_name',\n",
    "}).cache()\n",
    "\n",
    "raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the list of sources in the longlist. We'll use this to update the values in the columns later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = tuple(raw.cut('Source').distinct().values('Source'))\n",
    "sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recast the longlist to convert the Source column into a column per entry, and convert any non-None values into True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_table = raw.recast(\n",
    "    variablefield=\"Source\",\n",
    "    valuefield=\"Number\"\n",
    ").convert(\n",
    "    sources,\n",
    "    lambda x: True if x is not None else None\n",
    ")\n",
    "wide_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we will also add in new data from the result of stage 2.\n",
    "\n",
    "1. `location` Manually set locations \n",
    "2. `companies` Company data from Companies house (direct and fuzzy matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = etl.fromcsv(RAW_DATA / 'landscape-locations.csv').lookupone('organisation', ['latitude', 'longitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Direct and fuzzy data is loaded from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = duckdb.connect(RAW_DATA / 'company-data.db', read_only=True)\n",
    "db.query(f'''\n",
    "         CREATE OR REPLACE TEMP TABLE tCompanies AS\n",
    "              SELECT match as organisation, CompanyNumber as company_number, type, score\n",
    "                     FROM read_csv('{ WORKING / '2-company-match-fuzzy.csv' }')\n",
    "              UNION ALL\n",
    "              SELECT organisation, charity_company_registration_number AS company_number, 'charity' AS type, 100 AS score\n",
    "                     FROM read_csv('{ WORKING / '2-charity-match-direct.csv' }')\n",
    "              UNION ALL\n",
    "              SELECT *, 'direct' AS type, 100 as score\n",
    "                     FROM read_csv('{ WORKING / '2-company-match-direct.csv' }');\n",
    "         CREATE OR REPLACE TEMP TABLE tCharities AS\n",
    "              SELECT *\n",
    "                     FROM read_csv('{ WORKING / '2-charity-match-direct.csv' }');\n",
    "         CREATE OR REPLACE TEMP TABLE tSicCodes AS\n",
    "              SELECT *\n",
    "              FROM read_csv('{ WORKING / '2-sic-codes.csv' }');\n",
    "         CREATE OR REPLACE TEMP TABLE tPostcodes AS\n",
    "              SELECT pcds AS postcode, lat, long\n",
    "              FROM read_csv('{ DATA / 'reference/onspd_extract.csv' }')\n",
    "              WHERE oslaua == 'E08000021';\n",
    "         CREATE OR REPLACE TEMP TABLE tCompanyExtract AS\n",
    "              SELECT\n",
    "                    CompanyName as registered_name,\n",
    "                    CompanyNumber as company_number,\n",
    "                    \"URI\" as uri,\n",
    "                    \"RegAddress.PostTown\" as post_town,\n",
    "                    \"RegAddress.PostCode\" as postcode,\n",
    "                    CompanyCategory as company_category,\n",
    "                    CompanyStatus as company_status,\n",
    "                    [x for x in [\n",
    "                            \"SICCode.SicText_1\",\n",
    "                            \"SICCode.SicText_2\",\n",
    "                            \"SICCode.SicText_3\",\n",
    "                            \"SICCode.SicText_4\"\n",
    "                    ] if x is not NULL] as sic_code,\n",
    "                    IncorporationDate as incorporation_date,\n",
    "                    DissolutionDate as dissolution_date,\n",
    "                    \"Accounts.AccountCategory\" as accounts_category,\n",
    "                    lat AS latitude, long as longitude,\n",
    "              FROM CompanyData c\n",
    "              JOIN tPostcodes p\n",
    "              ON c.\"RegAddress.PostCode\" == p.postcode;\n",
    "              ;\n",
    "         ''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.query('''\n",
    "    SELECT * from tCompanies;\n",
    "         ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = etl.fromdataframe(\n",
    "    db.query('''\n",
    "             SELECT m.organisation as organisation,\n",
    "                c.CompanyName as registered_name,\n",
    "                c.CompanyNumber as company_number,\n",
    "                m.type,\n",
    "                m.score,\n",
    "                \"URI\" as uri,\n",
    "                \"RegAddress.PostTown\" as post_town,\n",
    "                \"RegAddress.PostCode\" as postcode,\n",
    "                CompanyCategory as company_category,\n",
    "                CompanyStatus as company_status,\n",
    "                [x for x in [\n",
    "                        \"SICCode.SicText_1\",\n",
    "                        \"SICCode.SicText_2\",\n",
    "                        \"SICCode.SicText_3\",\n",
    "                        \"SICCode.SicText_4\"\n",
    "                ] if x is not NULL] as sic_code,\n",
    "                IncorporationDate as incorporation_date,\n",
    "                DissolutionDate as dissolution_date,\n",
    "                \"Accounts.AccountCategory\" as accounts_category\n",
    "             FROM tCompanies m\n",
    "             JOIN CompanyData c\n",
    "             ON m.company_number == c.CompanyNumber;\n",
    "             ''').df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_by_sic = etl.fromdataframe(\n",
    "    db.query(f'''\n",
    "             SELECT DISTINCT c.*\n",
    "             FROM (\n",
    "               SELECT e.*\n",
    "               FROM tCompanyExtract e\n",
    "               LEFT JOIN (SELECT company_number FROM tCompanies) r\n",
    "               ON e.company_number == r.company_number\n",
    "               WHERE r.company_number IS NULL\n",
    "             ) c\n",
    "             JOIN tSicCodes s\n",
    "             ON list_contains(c.sic_code, s.sic_code)\n",
    "             ORDER BY c.company_number;\n",
    "             ''').df()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "charities = etl.fromdataframe(\n",
    "    db.query('''\n",
    "             SELECT\n",
    "             l.organisation,\n",
    "             c.charity_name,\n",
    "             c.registered_charity_number,\n",
    "             c.charity_company_registration_number,\n",
    "             charity_contact_postcode,\n",
    "             charity_contact_web,\n",
    "             latest_income AS charity_latest_income,\n",
    "             latest_expenditure AS charity_latest_expenditure\n",
    "             FROM Charities c\n",
    "             JOIN tCharities l\n",
    "             ON c.registered_charity_number == l.registered_charity_number\n",
    "             ''').df()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_data = companies.dictlookupone('organisation')\n",
    "charity_data = charities.dictlookupone('organisation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the new landscape table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "landscape_matched = (\n",
    "    wide_table\n",
    "    .addfield('location', lambda r: location.get(r.organisation, ()))\n",
    "    .unpack('location', newfields=['latitude', 'longitude'])\n",
    "    .addfield('company_data', lambda r: company_data.get(r.organisation, {}))\n",
    "    .unpackdict('company_data', keys=[\n",
    "        'company_category',\n",
    "        'accounts_category',\n",
    "        'company_number',\n",
    "        'company_status',\n",
    "        'dissolution_date',\n",
    "        'incorporation_date',\n",
    "        'post_town',\n",
    "        'postcode',\n",
    "        'sic_code',\n",
    "        'uri',\n",
    "        'type', 'score'\n",
    "    ])\n",
    "    .convert('postcode', normalise_postcode)\n",
    "    .addfield('charity_data', lambda r: charity_data.get(r.organisation, {}))\n",
    "    .unpackdict('charity_data', keys=[\n",
    "        'charity_name',\n",
    "        'registered_charity_number',\n",
    "        'charity_company_registration_number',\n",
    "        'charity_contact_postcode',\n",
    "        'charity_contact_web',\n",
    "        'charity_latest_expenditure',\n",
    "        'charity_latest_income',\n",
    "    ])\n",
    ")\n",
    "\n",
    "landscape = (\n",
    "    etl\n",
    "    .cat(landscape_matched, company_by_sic)\n",
    "    .convert('postcode', lambda x: postcode_lookup.get(x, { 'pcds': x }))\n",
    "    .unpackdict('postcode', keys=['pcds', 'lat', 'long', 'oslaua'])\n",
    "    .convert('latitude', lambda x, r: r['lat'], pass_row=True, where=lambda r: r['latitude'] == None and r['lat'] != None)\n",
    "    .convert('longitude', lambda x, r: r['long'], pass_row=True, where=lambda r: r['longitude'] == None and r['long'] != None)\n",
    "    .cutout('lat', 'long')\n",
    "    .convert('organisation', lambda x, r: x or r.registered_name, pass_row=True)\n",
    "    .cutout('registered_name')\n",
    "    .convert('sic_code', list)\n",
    "    .sort('organisation')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landscape.selectnotnone('company_number').duplicates('company_number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landscape.selectnotnone('registered_charity_number').select(lambda r: r.company_number != r.charity_company_registration_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, write the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "landscape.tocsv(DATA / 'culture_landscape.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landscape.cut('sic_code').selectnotnone('sic_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "northumbria-culture-connect-dQ7VTDtt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
